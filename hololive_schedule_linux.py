#!/usr/bin/env python

# Required additional packages:
# 1. bs4 (html analyse)
# 2. requests (get webpage)

from bs4 import BeautifulSoup
import requests as req
import re
from requests.cookies import RequestsCookieJar
import os
import time
import datetime

start = time.time()


# English name of the members
en_name = {
    'ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–': 'Hololive',
    'ã¨ãã®ãã‚‰': 'Tokino Sora',
    'ãƒ­ãƒœå­ã•ã‚“': 'Roboco',
    'ã•ãã‚‰ã¿ã“': 'Sakura Miko',
    'æ˜Ÿè¡—ã™ã„ã›ã„': 'Hoshimachi Suisei',
    'å¤œç©ºãƒ¡ãƒ«': 'Yozora Mel',
    'å¤è‰²ã¾ã¤ã‚Š': 'Natsuiro Matsuri',
    'èµ¤äº•ã¯ã‚ã¨': 'Akai Haato',
    'ã‚¢ã‚­ãƒ­ã‚¼': 'Aki Rosenthal',
    'ç™½ä¸Šãƒ•ãƒ–ã‚­': 'Shirakami Fubuki',
    'æ¹Šã‚ãã‚': 'Minato Aqua',
    'ç´«å’²ã‚·ã‚ªãƒ³': 'Murasaki Shion',
    'ç™¾é¬¼ã‚ã‚„ã‚': 'Nakiri Ayame',
    'ç™’æœˆã¡ã‚‡ã“': 'Yuzuki Choco',
    'å¤§ç©ºã‚¹ãƒãƒ«': 'Oozora Subaru',
    'å¤§ç¥žãƒŸã‚ª': 'Ookami Mio',
    'çŒ«åˆãŠã‹ã‚†': 'Nekomata Okayu',
    'æˆŒç¥žã“ã‚ã­': 'Inugami Korone',
    'å…Žç”°ãºã“ã‚‰': 'Usada Pekora',
    'æ½¤ç¾½ã‚‹ã—ã‚': 'Uruha Rushia',
    'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢': 'Shiranui Flare',
    'ç™½éŠ€ãƒŽã‚¨ãƒ«': 'Shirogane Noel',
    'å®é˜ãƒžãƒªãƒ³': 'Houshou Marine',
    'å¤©éŸ³ã‹ãªãŸ': 'Amane Kanata',
    'æ¡ç”Ÿã‚³ã‚³': 'Kiryu Coco',
    'è§’å·»ã‚ãŸã‚': 'Tsunomaki Watame',
    'å¸¸é—‡ãƒˆãƒ¯': 'Tokoyami Towa',
    'å§«æ£®ãƒ«ãƒ¼ãƒŠ': 'Himemori Luna',
    'AZKi': 'AZKi',
    'Risu': 'Ayunda Risu',
    'Moona': 'Moona Hoshinova',
    'Iofi': 'Airani Iofifteen',
    'å¤•åˆ»ãƒ­ãƒ™ãƒ«': 'Yukoku Roberu',
    'å¥æ‰‹ã‚¤ãƒ…ãƒ«': 'Kanade Izuru',
    'æœˆä¸‹ã‚«ã‚ªãƒ«': 'Tsukishita Kaoru',
    'èŠ±å’²ã¿ã‚„ã³': 'Hanasaki Miyabi',
    'é¡è¦‹ã‚­ãƒ©': 'Kagami Kira',
    'ã‚¢ãƒ«ãƒ©ãƒ³ãƒ‡ã‚£ã‚¹': 'Arurandeisu',
    'å¾‹å¯': 'Rikka',
    'ã‚¢ã‚¹ãƒ†ãƒ«ãƒ»ãƒ¬ãƒ€': 'Astel Leda',
    'å²¸å ‚å¤©çœŸ': 'Kishido Temma',
    'å½±å±±ã‚·ã‚¨ãƒ³': 'Kageyama Shien',
    'è’å’¬ã‚ªã‚¦ã‚¬': 'Aragami Oga',
    'ãƒ›ãƒ­ã‚¹ã‚¿ãƒ¼ã‚º': 'Holostars',
    'é›ªèŠ±ãƒ©ãƒŸã‚£': 'Yukihana Lamy',
    'ç…ç™½ã¼ãŸã‚“': 'Shishiro Botan',
    'å°¾ä¸¸ãƒãƒ«ã‚«': 'Omaru Polka',
    'æ¡ƒéˆ´ã­ã­': 'Momosuzu Nene',
    'é­”ä¹ƒã‚¢ãƒ­ã‚¨': 'Mano Aloe',
    'Ina': "Ninomae Ina'nis",
    'Gura': 'Gawr Gura',
    'Amelia': 'Watson Amelia',
    'Calli': 'Mori Calliope',
    'Kiara': 'Takanashi Kiara'
}


# Emoji of the members
emoji = {
    'ã¨ãã®ãã‚‰': '',
    'ãƒ­ãƒœå­ã•ã‚“': 'ðŸ¤–',
    'ã•ãã‚‰ã¿ã“': 'ðŸ’®',
    'æ˜Ÿè¡—ã™ã„ã›ã„': 'â˜„ï¸',
    'å¤œç©ºãƒ¡ãƒ«': 'ðŸŒŸ',
    'å¤è‰²ã¾ã¤ã‚Š': 'ðŸ®',
    'èµ¤äº•ã¯ã‚ã¨': 'â¤ï¸',
    'ã‚¢ã‚­ãƒ­ã‚¼': 'ðŸŽ',
    'ç™½ä¸Šãƒ•ãƒ–ã‚­': 'ðŸŒ½',
    'æ¹Šã‚ãã‚': 'âš“ï¸',
    'ç´«å’²ã‚·ã‚ªãƒ³': 'ðŸŒ™',
    'ç™¾é¬¼ã‚ã‚„ã‚': 'ðŸ˜ˆ',
    'ç™’æœˆã¡ã‚‡ã“': 'ðŸ«ðŸ’‹',
    'å¤§ç©ºã‚¹ãƒãƒ«': 'ðŸš‘',
    'å¤§ç¥žãƒŸã‚ª': 'ðŸŒ²',
    'çŒ«åˆãŠã‹ã‚†': 'ðŸ™',
    'æˆŒç¥žã“ã‚ã­': 'ðŸ¥',
    'å…Žç”°ãºã“ã‚‰': 'ðŸ‘¯',
    'æ½¤ç¾½ã‚‹ã—ã‚': 'ðŸ¦‹',
    'ä¸çŸ¥ç«ãƒ•ãƒ¬ã‚¢': 'ðŸ”¥',
    'ç™½éŠ€ãƒŽã‚¨ãƒ«': 'âš”',
    'å®é˜ãƒžãƒªãƒ³': 'ðŸ´â€â˜ ï¸',
    'å¤©éŸ³ã‹ãªãŸ': 'ðŸ’«',
    'æ¡ç”Ÿã‚³ã‚³': 'ðŸ‰',
    'è§’å·»ã‚ãŸã‚': 'ðŸ',
    'å¸¸é—‡ãƒˆãƒ¯': 'ðŸ‘¾',
    'å§«æ£®ãƒ«ãƒ¼ãƒŠ': 'ðŸ¬',
    'AZKi': 'ðŸŽ¤',
    'Risu': 'ðŸ¿',
    'Moona': 'ðŸ”®',
    'Iofi': 'ðŸŽ¨',
    'å¤•åˆ»ãƒ­ãƒ™ãƒ«': 'ðŸ·',
    'å¥æ‰‹ã‚¤ãƒ…ãƒ«': 'ðŸŽ¸',
    'æœˆä¸‹ã‚«ã‚ªãƒ«': 'ðŸ’…',
    'èŠ±å’²ã¿ã‚„ã³': 'ðŸŒº',
    'é¡è¦‹ã‚­ãƒ©': 'ðŸ’™',
    'ã‚¢ãƒ«ãƒ©ãƒ³ãƒ‡ã‚£ã‚¹': 'ðŸ•',
    'å¾‹å¯': 'âš™',
    'ã‚¢ã‚¹ãƒ†ãƒ«ãƒ»ãƒ¬ãƒ€': 'ðŸŽ­',
    'å²¸å ‚å¤©çœŸ': 'ðŸ¦”ðŸ’¨',
    'å½±å±±ã‚·ã‚¨ãƒ³': 'ðŸŸ£',
    'è’å’¬ã‚ªã‚¦ã‚¬': 'ðŸƒ',
    'ãƒ›ãƒ­ã‚¹ã‚¿ãƒ¼ã‚º': '',
    'é›ªèŠ±ãƒ©ãƒŸã‚£': 'â˜ƒï¸',
    'ç…ç™½ã¼ãŸã‚“': 'â™Œ',
    'å°¾ä¸¸ãƒãƒ«ã‚«': 'ðŸŽª',
    'æ¡ƒéˆ´ã­ã­': 'ðŸ¥Ÿ',
    'é­”ä¹ƒã‚¢ãƒ­ã‚¨': 'ðŸ‘…',
    'Ina': 'ðŸ™',
    'Gura': 'ðŸ”±',
    'Amelia': 'ðŸ”Ž',
    'Calli': 'ðŸ’€',
    'Kiara': 'ðŸ”'
}


# Designed UA header for HTTP-GET request
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36",
}


# Get cookie from domain schedule.hololive.tv
cookie_local = {}
resp = req.get("https://schedule.hololive.tv/lives/all", headers=headers)
cookie_local = resp.cookies
# Set the timezone as UTC in cookie to get schedule in UTC timezone
cookie_local.set("timezone", "UTC", domain="schedule.hololive.tv")


# Get HTML response of the schedule webpage
def get_html():
    resp = req.get("https://schedule.hololive.tv/lives/all",
                   cookies=cookie_local)
    return resp


# Get the nodes contain schedule info
# (The real live schedule is a div tag which class is 'tab-content')
def get_raw_schedule(html):
    soup = BeautifulSoup(html.text, "lxml")
    return soup.find_all(class_="tab-content")


# Traverse all tag nodes and classify them as tags contain date,
# time, VTuber's name and liveroom link, using class-id
def tag_classify(tag):
    if(tag.has_attr("class")):
        class_list = tag['class']
        # Tags contain date strings always with a class-id 'holodule navbar-text'
        if('holodule' in class_list
                and 'navbar-text' in class_list):
            return "date"
        # Tags contain time strings always with a class-id contains 'datetime'
        elif('datetime' in class_list):
            return "time"
        # Tags contain VTuber name always with a class-id contains 'text-right name'
        elif('col' in class_list and 'text-right' in class_list and 'name' in class_list):
            return "name"
        # Tags contain liveroom link always with a class-id contains 'thumbnail'
        elif('thumbnail' in class_list):
            return "link"
        else:
            return "others"
    else:
        return "others"


# Confirm if the VTuber is streaming now
# (The VTubers who are streaming will have a red border around the liveroom info card on the schedule webpage)
def is_streaming(tag):
    if(tag.has_attr("style")):
        style_list = tag['style']
        if('border: 3px red solid' in style_list):
            return True
        else:
            return False
    else:
        return False


# Format the strings from tag nodes
def format_string(string):
    return string.replace("\n", "").replace("\t", "").replace("\r", "").replace("None", "").replace(" ", "")


# Confirm if a VTuber's live is not started
# (The liveroom about to start will have strings contains 'scheduledStartTime' in their webpages)
def is_upcoming(tag):
    start = time.time()
    resp = req.get(tag['href'])
    upcoming_flag = re.search("scheduledStartTime", resp.text)
    if(upcoming_flag != None):
        end = time.time()
        print("module is_upcoming: ")
        print(end-start)
        return True
    else:
        end = time.time()
        print("module is_upcoming: ")
        print(end-start)
        return False


# Auto detect timezone and convert UTC time (on the webpage) to user's loacl time
def utc_2_localtime(utc):
    utc_t = datetime.datetime.strptime(utc, "%m/%d %H:%M")
    local_timestamp = time.time()
    local_time = datetime.datetime.fromtimestamp(local_timestamp)
    utc_time = datetime.datetime.utcfromtimestamp(local_timestamp)
    offset = local_time - utc_time
    local = utc_t + offset
    return (datetime.datetime.strftime(local, "%m/%d %H:%M"))


# Get current time
def get_current_time():
    timestamp = time.time()
    local = datetime.datetime.fromtimestamp(timestamp)
    return (datetime.datetime.strftime(local, "%m/%d %H:%M"))


# Get the tag nodes contain schedule info
raw_schedule = get_raw_schedule(get_html())
# Date status (changed when analyse new date)
date = "date_dummy_string"
schedule = []                                       # Blank schedule list
live = {}                                           # Blank liveroom dictionary
timezone = time.strftime("%z", time.localtime())    # User's timezone


# Analyse tag nodes
for tag in raw_schedule[0].find_all():
    # Tags contain date string detected (like '06/30(æ—¥)'), update date value
    if(tag_classify(tag) == "date"):
        date = format_string(tag.string)[0:5]       # Drop week info
    # Tags contain time string detected (like '14:00'),
    # combine date and time as a key in the dictionary
    elif(tag_classify(tag) == "time"):
        for time_string in tag.strings:
            if(time_string.replace("\n", "").replace("\t", "").replace("\r", "").replace("None", "").replace(" ", "") != ""):
                live['time'] = utc_2_localtime(
                    date+" "+format_string(time_string))
                # Streaming time is further than current time,
                # which means the stream is not beginning
                if(live['time'] > get_current_time()):
                    live['status'] = 'upcoming'
    # Tags contain VTuber's name string detected (like 'Risu'),
    # insert the name as a key in the dictionary
    elif(tag_classify(tag) == "name"):
        live['host'] = format_string(tag.string)
    # Tags contain liveroom link detected,
    # get the status of the liveroom (Stream over, Streaming now or Stream will start)
    # and insert different key in the dictionary
    elif(tag_classify(tag) == "link"):
        live['link'] = tag['href']
        if(is_streaming(tag) is True):
            live['status'] = 'streaming'
        else:
            live['status'] = 'over'
    # If all keys of a dictionary is inserted, append it into the schedule list
    if(len(live) == 4):
        schedule.append(live)
        live = {}   # Clear the dictionary for new info


end = time.time()
time_taken = str(end - start)

print(" ")
print("---")
print("---")
print("Streaming now")
print("---")
for stream_live in schedule:
    if(stream_live['status'] == 'streaming'):
        print("ðŸ”´ "+en_name.get(str(stream_live['host']), "")+" "
            + " | href=" + stream_live['link'])
print("---")
print("---")
print("Streaming later")
print("---")
for upcoming_live in schedule:
    if(upcoming_live['status'] == 'upcoming'):
        print(upcoming_live['time']+" "
                +en_name.get(str(upcoming_live['host']), "")+" "
                +" | href="+upcoming_live['link'])
    
